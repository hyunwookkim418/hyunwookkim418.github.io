<!DOCTYPE html>
<html lang="en">

<head>
    <meta name="title" property="og:title" content="Understanding Word2Vec">
    <meta property="og:url" content="https://example.com/word2vec">
    <meta property="og:type" content="website">
    <meta property="og:title" content="Understanding Word2Vec">
    <meta property="og:description" content="An introduction to Word2Vec, its methodology, and its applications in generating vector representations of words.">
    <meta property="og:image" content="https://example.com/image.png">

    <title>Understanding Word2Vec</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="ionicons/css/ionicons.min.css" rel="stylesheet">
    <link href="css/animate.min.css" rel="stylesheet">
    <link href="css/aos.css" rel="stylesheet">
    <link href="css/style.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Maven+Pro&display=swap" rel="stylesheet">

    <style>
        body {
            background-color: #f8f9fa;
            color: #343a40;
            font-family: 'Maven Pro', sans-serif;
        }

        h1 {
            margin-top: 20px;
            font-size: 2.5rem;
            text-align: center;
            color: #007bff;
        }

        h2 {
            margin-top: 30px;
            font-size: 2rem;
            color: #343a40;
        }

        p {
            font-size: 1.1rem;
            line-height: 1.6;
        }

        ul {
            margin: 20px 0;
            padding-left: 20px;
        }

        .back-link {
            margin-top: 30px;
            display: block;
            text-align: center;
            font-size: 1.2rem;
        }

        .container {
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background: white;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
        }
    </style>
</head>

<body>
    <div class="container">
        <h1>Understanding Word2Vec</h1>

        <h2>Limitations of One-Hot Encoding</h2>
        <p>One-hot encoding does not represent similarity because the distance between every pair of words is the same. Additionally, as the group of words grows larger, the dimension of the vector also increases, which causes inefficiency in calculations.</p>

        <h2>Word2Vec as a Solution</h2>
        <p>One solution is to use embeddings instead of encoding. The main purpose of Word2Vec is to represent the relationships between words more accurately using low-dimensional vectors, such as 2-dimensional vectors.</p>

        <h2>How Word2Vec Works</h2>
        <p>Word2Vec is a method for generating 2-dimensional vector representations based on measuring the similarity between neighboring words within sentences in a given dataset. Word2Vec assumes that neighboring words are more likely to have similar meanings to other words.</p>

        <p>Simply put, we provide sentences as input. The hidden layer in the middle uses Word2Vec. It returns embedding values by multiplying the initial one-hot encoding values by the weights of the hidden (linear) neurons. Thus, Word2Vec provides 2-dimensional vectors, such as [1, 1].</p>

        <h2>CBOW and Skip-Gram</h2>
        <p>Word2Vec employs CBOW (Continuous Bag of Words) or Skip-gram to learn similarities between words. CBOW predicts a word in the blank by utilizing neighboring words, while Skip-gram predicts neighboring words by utilizing the word in the blank. It does not use cosine similarity (angle) or Euclidean similarity (distance).</p>

        <a href="../blogpost.html" class="back-link">Back to Blog</a>
    </div>
</body>

</html>
